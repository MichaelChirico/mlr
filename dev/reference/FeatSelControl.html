<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Feature selection method used by selectFeatures.
The methods used here follow a wrapper approach, described in
Kohavi and John (1997) (see references).
The following optimization algorithms are available:
FeatSelControlExhaustive
Exhaustive search. All feature sets (up to a certain number
of features max.features) are searched.

FeatSelControlRandom
Random search. Features vectors are randomly drawn,
up to a certain number of features max.features.
A feature is included in the current set with probability prob.
So we are basically drawing (0,1)-membership-vectors, where each element
is Bernoulli(prob) distributed.

FeatSelControlSequential
Deterministic forward or backward search. That means extending
(forward) or shrinking (backward) a feature set.
Depending on the given method different approaches are taken.
sfs Sequential Forward Search: Starting from an empty model, in each step the feature increasing
the performance measure the most is added to the model.
sbs Sequential Backward Search: Starting from a model with all features, in each step the feature
decreasing the performance measure the least is removed from the model.
sffs Sequential Floating Forward Search: Starting from an empty model, in each step the algorithm
chooses the best model from all models with one additional feature and from all models with one
feature less.
sfbs Sequential Floating Backward Search: Similar to sffs but starting with a full model.

FeatSelControlGA
Search via genetic algorithm.
The GA is a simple (mu, lambda) or (mu + lambda) algorithm,
depending on the comma setting.
A comma strategy selects a new population of size mu out of the
lambda &amp;gt; mu offspring.
A plus strategy uses the joint pool of mu parents and lambda offspring
for selecting mu new candidates.
Out of those mu features, the new lambda features are generated
by randomly choosing pairs of parents. These are crossed over and crossover.rate
represents the probability of choosing a feature from the first parent instead of
the second parent.
The resulting offspring is mutated, i.e., its bits are flipped with
probability mutation.rate. If max.features is set, offspring are
repeatedly generated until the setting is satisfied.



"><title>Create control structures for feature selection. — FeatSelControl • mlr</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><link href="../deps/_Roboto-0.4.0/font.css" rel="stylesheet"><link href="../deps/_JetBrains%20Mono-0.4.0/font.css" rel="stylesheet"><link href="../deps/_Roboto%20Slab-0.4.0/font.css" rel="stylesheet"><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Create control structures for feature selection. — FeatSelControl"><meta property="og:description" content="Feature selection method used by selectFeatures.
The methods used here follow a wrapper approach, described in
Kohavi and John (1997) (see references).
The following optimization algorithms are available:
FeatSelControlExhaustive
Exhaustive search. All feature sets (up to a certain number
of features max.features) are searched.

FeatSelControlRandom
Random search. Features vectors are randomly drawn,
up to a certain number of features max.features.
A feature is included in the current set with probability prob.
So we are basically drawing (0,1)-membership-vectors, where each element
is Bernoulli(prob) distributed.

FeatSelControlSequential
Deterministic forward or backward search. That means extending
(forward) or shrinking (backward) a feature set.
Depending on the given method different approaches are taken.
sfs Sequential Forward Search: Starting from an empty model, in each step the feature increasing
the performance measure the most is added to the model.
sbs Sequential Backward Search: Starting from a model with all features, in each step the feature
decreasing the performance measure the least is removed from the model.
sffs Sequential Floating Forward Search: Starting from an empty model, in each step the algorithm
chooses the best model from all models with one additional feature and from all models with one
feature less.
sfbs Sequential Floating Backward Search: Similar to sffs but starting with a full model.

FeatSelControlGA
Search via genetic algorithm.
The GA is a simple (mu, lambda) or (mu + lambda) algorithm,
depending on the comma setting.
A comma strategy selects a new population of size mu out of the
lambda &amp;gt; mu offspring.
A plus strategy uses the joint pool of mu parents and lambda offspring
for selecting mu new candidates.
Out of those mu features, the new lambda features are generated
by randomly choosing pairs of parents. These are crossed over and crossover.rate
represents the probability of choosing a feature from the first parent instead of
the second parent.
The resulting offspring is mutated, i.e., its bits are flipped with
probability mutation.rate. If max.features is set, offspring are
repeatedly generated until the setting is satisfied.



"><meta property="og:image" content="https://mlr.mlr-org.com/logo.png"><meta name="robots" content="noindex"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">mlr</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.19.0.9001</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-2">
      <ul class="navbar-nav me-auto"><li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-basics">Basics</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-basics">
    <a class="dropdown-item" href="../articles/tutorial/task.html">Task</a>
    <a class="dropdown-item" href="../articles/tutorial/learner.html">Learner</a>
    <a class="dropdown-item" href="../articles/tutorial/train.html">Train</a>
    <a class="dropdown-item" href="../articles/tutorial/predict.html">Predict</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/preproc.html">Preprocessing</a>
    <a class="dropdown-item" href="../articles/tutorial/tune.html">Tuning</a>
    <a class="dropdown-item" href="../articles/tutorial/resample.html">Resampling</a>
    <a class="dropdown-item" href="../articles/tutorial/benchmark_experiments.html">Benchmarking</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/parallelization.html">Parallelization</a>
    <a class="dropdown-item" href="../articles/tutorial/performance.html">Performance</a>
    <a class="dropdown-item" href="../articles/tutorial/visualization.html">Visualization</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/usecase_regression.html">Use case - Regression</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-advanced">Advanced</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-advanced">
    <a class="dropdown-item" href="../articles/tutorial/configureMlr.html">mlr Configuration</a>
    <a class="dropdown-item" href="../articles/tutorial/wrapper.html">Wrapped Learners</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/impute.html">Imputation</a>
    <a class="dropdown-item" href="../articles/tutorial/bagging.html">Generic Bagging</a>
    <a class="dropdown-item" href="../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    <a class="dropdown-item" href="../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    <a class="dropdown-item" href="../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    <a class="dropdown-item" href="../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    <a class="dropdown-item" href="../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    <a class="dropdown-item" href="../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    <a class="dropdown-item" href="../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    <a class="dropdown-item" href="../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    <a class="dropdown-item" href="../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    <a class="dropdown-item" href="../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/multilabel.html">Multilabel Classification</a>
    <a class="dropdown-item" href="../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    <a class="dropdown-item" href="../articles/tutorial/handling_of_spatial_data.html">Spatial Data</a>
    <a class="dropdown-item" href="../articles/tutorial/functional_data.html">Functional Data</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-extending">Extending</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-extending">
    <a class="dropdown-item" href="../articles/tutorial/create_learner.html">Create Custom Learners</a>
    <a class="dropdown-item" href="../articles/tutorial/create_measure.html">Create Custom Measures</a>
    <a class="dropdown-item" href="../articles/tutorial/create_imputation.html">Create Custom Imputation Methods</a>
    <a class="dropdown-item" href="../articles/tutorial/create_filter.html">Create Custom Filters</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-appendix">Appendix</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-appendix">
    <a class="dropdown-item" href="../articles/tutorial/example_tasks.html">Integrated Tasks</a>
    <a class="dropdown-item" href="../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    <a class="dropdown-item" href="../articles/tutorial/measures.html">Integrated Measures</a>
    <a class="dropdown-item" href="../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../articles/tutorial/mlr_publications.html">mlr Publications</a>
    <a class="external-link dropdown-item" href="https://github.com/mlr-org/mlr-outreach">Talks, Videos and Workshops</a>
    <div class="dropdown-divider"></div>
    <a class="external-link dropdown-item" href="https://mlrmbo.mlr-org.com">mlrMBO</a>
    <a class="external-link dropdown-item" href="https://https://mlrcpo.mlr-org.com">mlrCPO</a>
    <a class="external-link dropdown-item" href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    <a class="external-link dropdown-item" href="http://openml.github.io/openml-r/">OpenML</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../news/index.html">Changelog</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlr-org/mlr/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Create control structures for feature selection.</h1>
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr/blob/HEAD/R/FeatSelControl.R" class="external-link"><code>R/FeatSelControl.R</code></a>, <a href="https://github.com/mlr-org/mlr/blob/HEAD/R/FeatSelControlExhaustive.R" class="external-link"><code>R/FeatSelControlExhaustive.R</code></a>, <a href="https://github.com/mlr-org/mlr/blob/HEAD/R/FeatSelControlGA.R" class="external-link"><code>R/FeatSelControlGA.R</code></a>, and 2 more</small>
      <div class="d-none name"><code>FeatSelControl.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Feature selection method used by <a href="selectFeatures.html">selectFeatures</a>.<br>
The methods used here follow a wrapper approach, described in
Kohavi and John (1997) (see references).</p>
<p>The following optimization algorithms are available:</p><dl><dt>FeatSelControlExhaustive</dt>
<dd><p>Exhaustive search. All feature sets (up to a certain number
of features <code>max.features</code>) are searched.</p></dd>

<dt>FeatSelControlRandom</dt>
<dd><p>Random search. Features vectors are randomly drawn,
up to a certain number of features <code>max.features</code>.
A feature is included in the current set with probability <code>prob</code>.
So we are basically drawing (0,1)-membership-vectors, where each element
is Bernoulli(<code>prob</code>) distributed.</p></dd>

<dt>FeatSelControlSequential</dt>
<dd><p>Deterministic forward or backward search. That means extending
(forward) or shrinking (backward) a feature set.
Depending on the given <code>method</code> different approaches are taken.<br><code>sfs</code> Sequential Forward Search: Starting from an empty model, in each step the feature increasing
the performance measure the most is added to the model.<br><code>sbs</code> Sequential Backward Search: Starting from a model with all features, in each step the feature
decreasing the performance measure the least is removed from the model.<br><code>sffs</code> Sequential Floating Forward Search: Starting from an empty model, in each step the algorithm
chooses the best model from all models with one additional feature and from all models with one
feature less.<br><code>sfbs</code> Sequential Floating Backward Search: Similar to <code>sffs</code> but starting with a full model.</p></dd>

<dt>FeatSelControlGA</dt>
<dd><p>Search via genetic algorithm.
The GA is a simple (<code>mu</code>, <code>lambda</code>) or (<code>mu</code> + <code>lambda</code>) algorithm,
depending on the <code>comma</code> setting.
A comma strategy selects a new population of size <code>mu</code> out of the
<code>lambda</code> &gt; <code>mu</code> offspring.
A plus strategy uses the joint pool of <code>mu</code> parents and <code>lambda</code> offspring
for selecting <code>mu</code> new candidates.
Out of those <code>mu</code> features, the new <code>lambda</code> features are generated
by randomly choosing pairs of parents. These are crossed over and <code>crossover.rate</code>
represents the probability of choosing a feature from the first parent instead of
the second parent.
The resulting offspring is mutated, i.e., its bits are flipped with
probability <code>mutation.rate</code>. If <code>max.features</code> is set, offspring are
repeatedly generated until the setting is satisfied.</p></dd>


</dl></div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="fu">makeFeatSelControlExhaustive</span><span class="op">(</span>
  same.resampling.instance <span class="op">=</span> <span class="cn">TRUE</span>,
  maxit <span class="op">=</span> <span class="cn">NA_integer_</span>,
  max.features <span class="op">=</span> <span class="cn">NA_integer_</span>,
  tune.threshold <span class="op">=</span> <span class="cn">FALSE</span>,
  tune.threshold.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,
  log.fun <span class="op">=</span> <span class="st">"default"</span>
<span class="op">)</span>

<span class="fu">makeFeatSelControlGA</span><span class="op">(</span>
  same.resampling.instance <span class="op">=</span> <span class="cn">TRUE</span>,
  impute.val <span class="op">=</span> <span class="cn">NULL</span>,
  maxit <span class="op">=</span> <span class="cn">NA_integer_</span>,
  max.features <span class="op">=</span> <span class="cn">NA_integer_</span>,
  comma <span class="op">=</span> <span class="cn">FALSE</span>,
  mu <span class="op">=</span> <span class="fl">10L</span>,
  <span class="va">lambda</span>,
  crossover.rate <span class="op">=</span> <span class="fl">0.5</span>,
  mutation.rate <span class="op">=</span> <span class="fl">0.05</span>,
  tune.threshold <span class="op">=</span> <span class="cn">FALSE</span>,
  tune.threshold.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,
  log.fun <span class="op">=</span> <span class="st">"default"</span>
<span class="op">)</span>

<span class="fu">makeFeatSelControlRandom</span><span class="op">(</span>
  same.resampling.instance <span class="op">=</span> <span class="cn">TRUE</span>,
  maxit <span class="op">=</span> <span class="fl">100L</span>,
  max.features <span class="op">=</span> <span class="cn">NA_integer_</span>,
  prob <span class="op">=</span> <span class="fl">0.5</span>,
  tune.threshold <span class="op">=</span> <span class="cn">FALSE</span>,
  tune.threshold.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,
  log.fun <span class="op">=</span> <span class="st">"default"</span>
<span class="op">)</span>

<span class="fu">makeFeatSelControlSequential</span><span class="op">(</span>
  same.resampling.instance <span class="op">=</span> <span class="cn">TRUE</span>,
  impute.val <span class="op">=</span> <span class="cn">NULL</span>,
  <span class="va">method</span>,
  alpha <span class="op">=</span> <span class="fl">0.01</span>,
  beta <span class="op">=</span> <span class="op">-</span><span class="fl">0.001</span>,
  maxit <span class="op">=</span> <span class="cn">NA_integer_</span>,
  max.features <span class="op">=</span> <span class="cn">NA_integer_</span>,
  tune.threshold <span class="op">=</span> <span class="cn">FALSE</span>,
  tune.threshold.args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,
  log.fun <span class="op">=</span> <span class="st">"default"</span>
<span class="op">)</span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>same.resampling.instance</dt>
<dd><p>(<code>logical(1)</code>)<br>
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p></dd>
<dt>maxit</dt>
<dd><p>(<code>integer(1)</code>)<br>
Maximal number of iterations. Note, that this is usually not equal to the number
of function evaluations.</p></dd>
<dt>max.features</dt>
<dd><p>(<code>integer(1)</code>)<br>
Maximal number of features.</p></dd>
<dt>tune.threshold</dt>
<dd><p>(<code>logical(1)</code>)<br>
Should the threshold be tuned for the measure at hand, after each feature set evaluation,
via <a href="tuneThreshold.html">tuneThreshold</a>?
Only works for classification if the predict type is “prob”.
Default is <code>FALSE</code>.</p></dd>
<dt>tune.threshold.args</dt>
<dd><p>(<a href="https://rdrr.io/r/base/list.html" class="external-link">list</a>)<br>
Further arguments for threshold tuning that are passed down to <a href="tuneThreshold.html">tuneThreshold</a>.
Default is none.</p></dd>
<dt>log.fun</dt>
<dd><p>(<code>function</code> | <code>character(1)</code>)<br>
Function used for logging. If set to “default” (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to “memory” the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="https://rdrr.io/r/base/gc.html" class="external-link">gc</a>).
See the implementation for details.</p></dd>
<dt>impute.val</dt>
<dd><p>(<a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a>)<br>
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="configureMlr.html">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p></dd>
<dt>comma</dt>
<dd><p>(<code>logical(1)</code>)<br>
Parameter of the GA feature selection, indicating whether to use a (<code>mu</code>, <code>lambda</code>)
or (<code>mu</code> + <code>lambda</code>) GA. The default is <code>FALSE</code>.</p></dd>
<dt>mu</dt>
<dd><p>(<code>integer(1)</code>)<br>
Parameter of the GA feature selection. Size of the parent population.</p></dd>
<dt>lambda</dt>
<dd><p>(<code>integer(1)</code>)<br>
Parameter of the GA feature selection. Size of the children population (should be smaller
or equal to <code>mu</code>).</p></dd>
<dt>crossover.rate</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Parameter of the GA feature selection. Probability of choosing a bit from the first parent
within the crossover mutation.</p></dd>
<dt>mutation.rate</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Parameter of the GA feature selection. Probability of flipping a feature bit, i.e. switch
between selecting / deselecting a feature.</p></dd>
<dt>prob</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Parameter of the random feature selection. Probability of choosing a feature.</p></dd>
<dt>method</dt>
<dd><p>(<code>character(1)</code>)<br>
Parameter of the sequential feature selection. A character representing the method. Possible
values are <code>sfs</code> (forward search), <code>sbs</code> (backward search), <code>sffs</code>
(floating forward search) and <code>sfbs</code> (floating backward search).</p></dd>
<dt>alpha</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Parameter of the sequential feature selection.
Minimal required value of improvement difference for a forward / adding step.
Default is 0.01.</p></dd>
<dt>beta</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Parameter of the sequential feature selection.
Minimal required value of improvement difference for a backward / removing step.
Negative values imply that you allow a slight decrease for the removal of a feature.
Default is -0.001.</p></dd>
</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>(FeatSelControl). The specific subclass is one of
FeatSelControlExhaustive, FeatSelControlRandom,
FeatSelControlSequential, FeatSelControlGA.</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Ron Kohavi and George H. John,
Wrappers for feature subset selection, Artificial Intelligence Volume 97, 1997, 273-324.
<a href="http://ai.stanford.edu/~ronnyk/wrappersPrint.pdf" class="external-link">http://ai.stanford.edu/~ronnyk/wrappersPrint.pdf</a>.<br></p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p>Other featsel: 
<code><a href="analyzeFeatSelResult.html">analyzeFeatSelResult</a>()</code>,
<code><a href="getFeatSelResult.html">getFeatSelResult</a>()</code>,
<code><a href="makeFeatSelWrapper.html">makeFeatSelWrapper</a>()</code>,
<code><a href="selectFeatures.html">selectFeatures</a>()</code></p></div>
    </div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Patrick Schratz, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.1.</p>
</div>

    </footer></div>

  

  

  </body></html>

