<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="mlr">
<title>Exploring Learner Predictions • mlr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><link href="../../deps/_Roboto-0.4.0/font.css" rel="stylesheet">
<link href="../../deps/_JetBrains%20Mono-0.4.0/font.css" rel="stylesheet">
<link href="../../deps/_Roboto%20Slab-0.4.0/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Exploring Learner Predictions">
<meta property="og:description" content="mlr">
<meta property="og:image" content="https://mlr.mlr-org.com/logo.png">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">mlr</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.19.0.9001</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-basics">Basics</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-basics">
    <a class="dropdown-item" href="../../articles/tutorial/task.html">Task</a>
    <a class="dropdown-item" href="../../articles/tutorial/learner.html">Learner</a>
    <a class="dropdown-item" href="../../articles/tutorial/train.html">Train</a>
    <a class="dropdown-item" href="../../articles/tutorial/predict.html">Predict</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/preproc.html">Preprocessing</a>
    <a class="dropdown-item" href="../../articles/tutorial/tune.html">Tuning</a>
    <a class="dropdown-item" href="../../articles/tutorial/resample.html">Resampling</a>
    <a class="dropdown-item" href="../../articles/tutorial/benchmark_experiments.html">Benchmarking</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/parallelization.html">Parallelization</a>
    <a class="dropdown-item" href="../../articles/tutorial/performance.html">Performance</a>
    <a class="dropdown-item" href="../../articles/tutorial/visualization.html">Visualization</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
  </div>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-advanced">Advanced</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-advanced">
    <a class="dropdown-item" href="../../articles/tutorial/configureMlr.html">mlr Configuration</a>
    <a class="dropdown-item" href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/impute.html">Imputation</a>
    <a class="dropdown-item" href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    <a class="dropdown-item" href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    <a class="dropdown-item" href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    <a class="dropdown-item" href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    <a class="dropdown-item" href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    <a class="dropdown-item" href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    <a class="dropdown-item" href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    <a class="dropdown-item" href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    <a class="dropdown-item" href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    <a class="dropdown-item" href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    <a class="dropdown-item" href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial/handling_of_spatial_data.html">Spatial Data</a>
    <a class="dropdown-item" href="../../articles/tutorial/functional_data.html">Functional Data</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-extending">Extending</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-extending">
    <a class="dropdown-item" href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    <a class="dropdown-item" href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    <a class="dropdown-item" href="../../articles/tutorial/create_imputation.html">Create Custom Imputation Methods</a>
    <a class="dropdown-item" href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-appendix">Appendix</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-appendix">
    <a class="dropdown-item" href="../../articles/tutorial/example_tasks.html">Integrated Tasks</a>
    <a class="dropdown-item" href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    <a class="dropdown-item" href="../../articles/tutorial/measures.html">Integrated Measures</a>
    <a class="dropdown-item" href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    <a class="external-link dropdown-item" href="https://github.com/mlr-org/mlr-outreach">Talks, Videos and Workshops</a>
    <div class="dropdown-divider"></div>
    <a class="external-link dropdown-item" href="https://mlrmbo.mlr-org.com">mlrMBO</a>
    <a class="external-link dropdown-item" href="https://https://mlrcpo.mlr-org.com">mlrCPO</a>
    <a class="external-link dropdown-item" href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    <a class="external-link dropdown-item" href="http://openml.github.io/openml-r/">OpenML</a>
    <div class="dropdown-divider"></div>
    <a class="dropdown-item" href="../../news/index.html">Changelog</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlr-org/mlr/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa fab fa-stack-overflow"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://mlr-org.com/">
    <span class="fa fa-rss"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>Exploring Learner Predictions</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr/blob/HEAD/vignettes/tutorial/partial_dependence.Rmd" class="external-link"><code>vignettes/tutorial/partial_dependence.Rmd</code></a></small>
      <div class="d-none name"><code>partial_dependence.Rmd</code></div>
    </div>

    
    
<p>Learners use features to learn a prediction function and make predictions, but the effect of those features is often not apparent. <code>mlr</code> can estimate the partial dependence of a learned function on a subset of the feature space using <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code>.</p>
<p>Partial dependence plots reduce the potentially high dimensional function estimated by the learner, and display a marginalized version of this function in a lower dimensional space. For example suppose <span class="math inline">\(Y = f(X) + \epsilon\)</span>, where <span class="math inline">\(\mathbb{E}[\epsilon|X] = 0\)</span>. With <span class="math inline">\((X, Y)\)</span> pairs drawn independently from this statistical model, a learner may estimate <span class="math inline">\(\hat{f}\)</span>, which, if <span class="math inline">\(X\)</span> is high dimensional, can be uninterpretable. Suppose we want to approximate the relationship between some subset of <span class="math inline">\(X\)</span>. We partition <span class="math inline">\(X\)</span> into two sets, <span class="math inline">\(X_s\)</span> and <span class="math inline">\(X_c\)</span> such that <span class="math inline">\(X = X_s \cup X_c\)</span>, where <span class="math inline">\(X_s\)</span> is a subset of <span class="math inline">\(X\)</span> of interest.</p>
<p>The partial dependence of <span class="math inline">\(f\)</span> on <span class="math inline">\(X_s\)</span> is</p>
<p><span class="math display">\[f_{X_s} = \mathbb{E}_{X_c}f(X_s, X_c).\]</span></p>
<p><span class="math inline">\(X_c\)</span> is integrated out. We use the following estimator:</p>
<p><span class="math display">\[\hat{f}_{X_s} = \frac{1}{N} \sum_{i = 1}^N \hat{f}(X_s, x_{ic}).\]</span></p>
<p>The individual conditional expectation of an observation can also be estimated using the above algorithm absent the averaging, giving <span class="math inline">\(\hat{f}^{(i)}_{X_s}\)</span>. This allows the discovery of features of <span class="math inline">\(\hat{f}\)</span> that may be obscured by an aggregated summary of <span class="math inline">\(\hat{f}\)</span>.</p>
<p>The partial derivative of the partial dependence function, <span class="math inline">\(\frac{\partial \hat{f}_{X_s}}{\partial X_s}\)</span>, and the individual conditional expectation function, <span class="math inline">\(\frac{\partial \hat{f}^{(i)}_{X_s}}{\partial X_s}\)</span>, can also be computed. For regression and survival tasks the partial derivative of a single feature <span class="math inline">\(X_s\)</span> is the gradient of the partial dependence function, and for classification tasks where the learner can output class probabilities the Jacobian. Note that if the learner produces discontinuous partial dependence (e.g., piecewise constant functions such as decision trees, ensembles of decision trees, etc.) the derivative will be 0 (where the function is not changing) or trending towards positive or negative infinity (at the discontinuities where the derivative is undefined). Plotting the partial dependence function of such learners may give the impression that the function is not discontinuous because the prediction grid is not composed of all discontinuous points in the predictor space. This results in a line interpolating that makes the function appear to be piecewise linear (where the derivative would be defined except at the boundaries of each piece).</p>
<p>The partial derivative can be informative regarding the additivity of the learned function in certain features. If <span class="math inline">\(\hat{f}^{(i)}_{X_s}\)</span> is an additive function in a feature <span class="math inline">\(X_s\)</span>, then its partial derivative will not depend on any other features (<span class="math inline">\(X_c\)</span>) that may have been used by the learner. Variation in the estimated partial derivative indicates that there is a region of interaction between <span class="math inline">\(X_s\)</span> and <span class="math inline">\(X_c\)</span> in <span class="math inline">\(\hat{f}\)</span>. Similarly, instead of using the mean to estimate the expected value of the function at different values of <span class="math inline">\(X_s\)</span>, instead computing the variance can highlight regions of interaction between <span class="math inline">\(X_s\)</span> and <span class="math inline">\(X_c\)</span>.</p>
<p>See <a href="http://arxiv.org/abs/1309.6392" class="external-link">Goldstein, Kapelner, Bleich, and Pitkin (2014)</a> for more details and their package <code>ICEbox</code> for the original implementation. The algorithm works for any supervised learner with classification, regression, and survival tasks.</p>
<div class="section level2">
<h2 id="generating-partial-dependences">Generating partial dependences<a class="anchor" aria-label="anchor" href="#generating-partial-dependences"></a>
</h2>
<p>Our implementation, following <code>mlr</code>’s <a href="visualization.html" target="_blank">visualization</a> pattern, consists of the above mentioned function <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code>, as well as two visualization functions, <code><a href="../../reference/plotPartialDependence.html">plotPartialDependence()</a></code> and <code>plotPartialDependenceGGVIS()</code>. The former generates input (objects of class <code><a href="../../reference/generatePartialDependenceData.html">PartialDependenceData()</a></code>) for the latter.</p>
<p>The first step executed by <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code> is to generate a feature grid for every element of the character vector <code>features</code> passed. The data are given by the <code>input</code> argument, which can be a <code><a href="../../reference/Task.html">Task()</a></code> or a <code>data.frame</code>. The feature grid can be generated in several ways. A uniformly spaced grid of length <code>gridsize</code> (default 10) from the empirical minimum to the empirical maximum is created by default, but arguments <code>fmin</code> and <code>fmax</code> may be used to override the empirical default (the lengths of <code>fmin</code> and <code>fmax</code> must match the length of <code>features</code>). Alternatively the feature data can be resampled, either by using a bootstrap or by subsampling.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lrn.classif</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, predict.type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span>
<span class="va">fit.classif</span> <span class="op">=</span> <span class="fu"><a href="../../reference/train.html">train</a></span><span class="op">(</span><span class="va">lrn.classif</span>, <span class="va">iris.task</span><span class="op">)</span>
<span class="va">pd</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="st">"Petal.Width"</span><span class="op">)</span>
<span class="co">## Loading required package: mmpf</span>
<span class="va">pd</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: iris-example</span>
<span class="co">## Features: Petal.Width</span>
<span class="co">## Target: Petal.Width</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: FALSE</span>
<span class="co">##     Class Probability Petal.Width</span>
<span class="co">## 1: setosa   0.4958234   0.1000000</span>
<span class="co">## 2: setosa   0.4558458   0.3666667</span>
<span class="co">## 3: setosa   0.3909992   0.6333333</span>
<span class="co">## 4: setosa   0.3175975   0.9000000</span>
<span class="co">## 5: setosa   0.2296299   1.1666667</span>
<span class="co">## 6: setosa   0.1552914   1.4333333</span>
<span class="co">## ... (#rows: 30, #cols: 3)</span></code></pre></div>
<p>As noted above, <span class="math inline">\(X_s\)</span> does not have to be unidimensional. If it is not, the <code>interaction</code> flag must be set to <code>TRUE</code>. Then the individual feature grids are combined using the Cartesian product, and the estimator above is applied, producing the partial dependence for every combination of unique feature values. If the <code>interaction</code> flag is <code>FALSE</code> (the default) then by default <span class="math inline">\(X_s\)</span> is assumed unidimensional, and partial dependencies are generated for each feature separately. The resulting output when <code>interaction = FALSE</code> has a column for each feature, and <code>NA</code> where the feature was not used.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.lst</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Petal.Width"</span>, <span class="st">"Petal.Length"</span><span class="op">)</span>, <span class="cn">FALSE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.lst</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##     Class Probability Petal.Width Petal.Length</span>
<span class="co">## 1: setosa   0.4958234   0.1000000           NA</span>
<span class="co">## 2: setosa   0.4558458   0.3666667           NA</span>
<span class="co">## 3: setosa   0.3909992   0.6333333           NA</span>
<span class="co">## 4: setosa   0.3175975   0.9000000           NA</span>
<span class="co">## 5: setosa   0.2296299   1.1666667           NA</span>
<span class="co">## 6: setosa   0.1552914   1.4333333           NA</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">pd.lst</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##        Class Probability Petal.Width Petal.Length</span>
<span class="co">## 1: virginica   0.2072951          NA     3.622222</span>
<span class="co">## 2: virginica   0.3102762          NA     4.277778</span>
<span class="co">## 3: virginica   0.4262447          NA     4.933333</span>
<span class="co">## 4: virginica   0.5688485          NA     5.588889</span>
<span class="co">## 5: virginica   0.6722758          NA     6.244444</span>
<span class="co">## 6: virginica   0.6735450          NA     6.900000</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.int</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Petal.Width"</span>, <span class="st">"Petal.Length"</span><span class="op">)</span>, <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">pd.int</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: iris-example</span>
<span class="co">## Features: Petal.Width, Petal.Length</span>
<span class="co">## Target: Petal.Width, Petal.Length</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: TRUE</span>
<span class="co">## Individual: FALSE</span>
<span class="co">##     Class Probability Petal.Width Petal.Length</span>
<span class="co">## 1: setosa   0.6322134         0.1     1.000000</span>
<span class="co">## 2: setosa   0.6322390         0.1     1.655556</span>
<span class="co">## 3: setosa   0.5933773         0.1     2.311111</span>
<span class="co">## 4: setosa   0.5055548         0.1     2.966667</span>
<span class="co">## 5: setosa   0.3857175         0.1     3.622222</span>
<span class="co">## 6: setosa   0.2995966         0.1     4.277778</span>
<span class="co">## ... (#rows: 300, #cols: 4)</span></code></pre></div>
<p>At each step in the estimation of <span class="math inline">\(\hat{f}_{X_s}\)</span> a set of predictions of length <span class="math inline">\(N\)</span> is generated. By default the mean prediction is used. For classification where <code>predict.type = "prob"</code> this entails the mean class probabilities. However, other summaries of the predictions may be used. For regression and survival tasks the function used here must either return one number or three, and, if the latter, the numbers must be sorted lowest to highest. For classification tasks the function must return a number for each level of the target feature.</p>
<p>As noted, the <code>fun</code> argument can be a function which returns three numbers (sorted low to high) for a regression task. This allows further exploration of relative feature importance. If a feature is relatively important, the bounds are necessarily tighter because the feature accounts for more of the variance of the predictions, i.e., it is “used” more by the learner. More directly setting <code>fun = var</code> identifies regions of interaction between <span class="math inline">\(X_s\)</span> and <span class="math inline">\(X_c\)</span>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lrn.regr</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span><span class="op">(</span><span class="st">"regr.ksvm"</span><span class="op">)</span>
<span class="va">fit.regr</span> <span class="op">=</span> <span class="fu"><a href="../../reference/train.html">train</a></span><span class="op">(</span><span class="va">lrn.regr</span>, <span class="va">bh.task</span><span class="op">)</span>
<span class="va">pd.regr</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.regr</span>, <span class="va">bh.task</span>, <span class="st">"lstat"</span>, fun <span class="op">=</span> <span class="va">median</span><span class="op">)</span>
<span class="va">pd.regr</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: BostonHousing-example</span>
<span class="co">## Features: lstat</span>
<span class="co">## Target: lstat</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: FALSE</span>
<span class="co">##        medv     lstat</span>
<span class="co">## 1: 24.92549  1.730000</span>
<span class="co">## 2: 23.76082  5.756667</span>
<span class="co">## 3: 22.37301  9.783333</span>
<span class="co">## 4: 20.69748 13.810000</span>
<span class="co">## 5: 19.57175 17.836667</span>
<span class="co">## 6: 18.95547 21.863333</span>
<span class="co">## ... (#rows: 10, #cols: 2)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.ci</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.regr</span>, <span class="va">bh.task</span>, <span class="st">"lstat"</span>,
  fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.25</span>, <span class="fl">.5</span>, <span class="fl">.75</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">pd.ci</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: BostonHousing-example</span>
<span class="co">## Features: lstat</span>
<span class="co">## Target: lstat</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: FALSE</span>
<span class="co">##        medv Function     lstat</span>
<span class="co">## 1: 21.34127 medv.25%  1.730000</span>
<span class="co">## 2: 20.77390 medv.25%  5.756667</span>
<span class="co">## 3: 19.85575 medv.25%  9.783333</span>
<span class="co">## 4: 18.70219 medv.25% 13.810000</span>
<span class="co">## 5: 16.54983 medv.25% 17.836667</span>
<span class="co">## 6: 14.80144 medv.25% 21.863333</span>
<span class="co">## ... (#rows: 30, #cols: 3)</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.classif</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="st">"Petal.Length"</span>, fun <span class="op">=</span> <span class="va">median</span><span class="op">)</span>
<span class="va">pd.classif</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: iris-example</span>
<span class="co">## Features: Petal.Length</span>
<span class="co">## Target: Petal.Length</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: FALSE</span>
<span class="co">##     Class Probability Petal.Length</span>
<span class="co">## 1: setosa  0.27958460     1.000000</span>
<span class="co">## 2: setosa  0.25023369     1.655556</span>
<span class="co">## 3: setosa  0.19970584     2.311111</span>
<span class="co">## 4: setosa  0.12498617     2.966667</span>
<span class="co">## 5: setosa  0.06180763     3.622222</span>
<span class="co">## 6: setosa  0.02892394     4.277778</span>
<span class="co">## ... (#rows: 30, #cols: 3)</span></code></pre></div>
<p>In addition to bounds based on a summary of the distribution of the conditional expectation of each observation, learners which can estimate the variance of their predictions can also be used. The argument <code>bounds</code> is a numeric vector of length two which is added (so the first number should be negative) to the point prediction to produce a confidence interval for the partial dependence. The default is the .025 and .975 quantiles of the Gaussian distribution.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit.se</span> <span class="op">=</span> <span class="fu"><a href="../../reference/train.html">train</a></span><span class="op">(</span><span class="fu"><a href="../../reference/makeLearner.html">makeLearner</a></span><span class="op">(</span><span class="st">"regr.randomForest"</span>, predict.type <span class="op">=</span> <span class="st">"se"</span><span class="op">)</span>, <span class="va">bh.task</span><span class="op">)</span>
<span class="va">pd.se</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.se</span>, <span class="va">bh.task</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"lstat"</span>, <span class="st">"crim"</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.se</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##       lower     medv    upper     lstat crim</span>
<span class="co">## 1: 12.58683 31.71303 50.83924  1.730000   NA</span>
<span class="co">## 2: 14.26528 26.01166 37.75805  5.756667   NA</span>
<span class="co">## 3: 13.45446 23.56351 33.67256  9.783333   NA</span>
<span class="co">## 4: 14.26956 22.10487 29.94017 13.810000   NA</span>
<span class="co">## 5: 12.90632 20.40292 27.89953 17.836667   NA</span>
<span class="co">## 6: 11.79286 19.75005 27.70724 21.863333   NA</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">pd.se</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##       lower     medv    upper lstat     crim</span>
<span class="co">## 1: 10.64117 21.69222 32.74327    NA 39.54849</span>
<span class="co">## 2: 10.62463 21.68560 32.74656    NA 49.43403</span>
<span class="co">## 3: 10.60889 21.67844 32.74800    NA 59.31957</span>
<span class="co">## 4: 10.51115 21.64946 32.78778    NA 69.20512</span>
<span class="co">## 5: 10.52775 21.65359 32.77944    NA 79.09066</span>
<span class="co">## 6: 10.52775 21.65359 32.77944    NA 88.97620</span></code></pre></div>
<p>As previously mentioned if the aggregation function is not used, i.e., it is the identity, then the conditional expectation of <span class="math inline">\(\hat{f}^{(i)}_{X_s}\)</span> is estimated. If <code>individual = TRUE</code> then <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code> returns <span class="math inline">\(n\)</span> partial dependence estimates made at each point in the prediction grid constructed from the features.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.ind.regr</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.regr</span>, <span class="va">bh.task</span>, <span class="st">"lstat"</span>, individual <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">pd.ind.regr</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: BostonHousing-example</span>
<span class="co">## Features: lstat</span>
<span class="co">## Target: lstat</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: TRUE</span>
<span class="co">##        medv n     lstat</span>
<span class="co">## 1: 29.48248 1  1.730000</span>
<span class="co">## 2: 27.70980 1  5.756667</span>
<span class="co">## 3: 25.43516 1  9.783333</span>
<span class="co">## 4: 22.99795 1 13.810000</span>
<span class="co">## 5: 20.73801 1 17.836667</span>
<span class="co">## 6: 18.92351 1 21.863333</span>
<span class="co">## ... (#rows: 5060, #cols: 3)</span></code></pre></div>
<p>The resulting output, particularly the element <code>data</code> in the returned object, has an additional column <code>idx</code> which gives the index of the observation to which the row pertains.</p>
<p>For classification tasks this index references both the class and the observation index.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.ind.classif</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="st">"Petal.Length"</span>, individual <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">pd.ind.classif</span>
<span class="co">## PartialDependenceData</span>
<span class="co">## Task: iris-example</span>
<span class="co">## Features: Petal.Length</span>
<span class="co">## Target: Petal.Length</span>
<span class="co">## Derivative: FALSE</span>
<span class="co">## Interaction: FALSE</span>
<span class="co">## Individual: TRUE</span>
<span class="co">##     Class Probability n Petal.Length</span>
<span class="co">## 1: setosa  0.30069555 1     1.000000</span>
<span class="co">## 2: setosa  0.24545844 1     1.655556</span>
<span class="co">## 3: setosa  0.13791545 1     2.311111</span>
<span class="co">## 4: setosa  0.04918890 1     2.966667</span>
<span class="co">## 5: setosa  0.01702062 1     3.622222</span>
<span class="co">## 6: setosa  0.01018729 1     4.277778</span>
<span class="co">## ... (#rows: 4500, #cols: 4)</span></code></pre></div>
<p>Partial derivatives can also be computed for individual partial dependence estimates and aggregate partial dependence. This is restricted to a single feature at a time. The derivatives of individual partial dependence estimates can be useful in finding regions of interaction between the feature for which the derivative is estimated and the features excluded.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.regr.der</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.regr</span>, <span class="va">bh.task</span>, <span class="st">"lstat"</span>, derivative <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.regr.der</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##          medv     lstat</span>
<span class="co">## 1: -0.2502111  1.730000</span>
<span class="co">## 2: -0.3561552  5.756667</span>
<span class="co">## 3: -0.4159729  9.783333</span>
<span class="co">## 4: -0.4218586 13.810000</span>
<span class="co">## 5: -0.3767553 17.836667</span>
<span class="co">## 6: -0.2914229 21.863333</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.regr.der.ind</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.regr</span>, <span class="va">bh.task</span>, <span class="st">"lstat"</span>, derivative <span class="op">=</span> <span class="cn">TRUE</span>,
  individual <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.regr.der.ind</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##          medv  n     lstat</span>
<span class="co">## 1: -0.1703899 15  1.730000</span>
<span class="co">## 2: -0.1649074 15  5.756667</span>
<span class="co">## 3: -0.1677604 15  9.783333</span>
<span class="co">## 4: -0.1790711 15 13.810000</span>
<span class="co">## 5: -0.1864755 15 17.836667</span>
<span class="co">## 6: -0.1706008 15 21.863333</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.classif.der</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="st">"Petal.Width"</span>, derivative <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.classif.der</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##     Class Probability Petal.Width</span>
<span class="co">## 1: setosa -0.08628906   0.1000000</span>
<span class="co">## 2: setosa -0.20992196   0.3666667</span>
<span class="co">## 3: setosa -0.26049715   0.6333333</span>
<span class="co">## 4: setosa -0.30221163   0.9000000</span>
<span class="co">## 5: setosa -0.33394805   1.1666667</span>
<span class="co">## 6: setosa -0.20736953   1.4333333</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">pd.classif.der.ind</span> <span class="op">=</span> <span class="fu"><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData</a></span><span class="op">(</span><span class="va">fit.classif</span>, <span class="va">iris.task</span>, <span class="st">"Petal.Width"</span>, derivative <span class="op">=</span> <span class="cn">TRUE</span>,
  individual <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pd.classif.der.ind</span><span class="op">$</span><span class="va">data</span><span class="op">)</span>
<span class="co">##     Class  Probability  n Petal.Width</span>
<span class="co">## 1: setosa -0.448458780 94   0.1000000</span>
<span class="co">## 2: setosa -0.695200956 94   0.3666667</span>
<span class="co">## 3: setosa -0.306311779 94   0.6333333</span>
<span class="co">## 4: setosa -0.069066116 94   0.9000000</span>
<span class="co">## 5: setosa -0.004061345 94   1.1666667</span>
<span class="co">## 6: setosa  0.038224205 94   1.4333333</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="plotting-partial-dependences">Plotting partial dependences<a class="anchor" aria-label="anchor" href="#plotting-partial-dependences"></a>
</h2>
<p>Results from <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code> and <code>generateFunctionalANOVAData()</code> can be visualized with <code><a href="../../reference/plotPartialDependence.html">plotPartialDependence()</a></code> and <code>plotPartialDependenceGGVIS()</code>.</p>
<p>With one feature and a regression task the output is a line plot, with a point for each point in the corresponding feature’s grid.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.regr</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
<p>With a classification task, a line is drawn for each class, which gives the estimated partial probability of that class for a particular point in the feature grid.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.classif</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-16-1.png" width="700"></p>
<p>For regression tasks, when the <code>fun</code> argument of <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code> is used, the bounds will automatically be displayed using a gray ribbon.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.ci</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-17-1.png" width="700"></p>
<p>The same goes for plots of partial dependences where the learner has <code>predict.type = "se"</code>.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.se</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-18-1.png" width="700"></p>
<p>When multiple features are passed to <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code> but <code>interaction = FALSE</code>, facetting is used to display each estimated bivariate relationship.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.lst</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-19-1.png" width="700"></p>
<p>When <code>interaction = TRUE</code> in the call to <code><a href="../../reference/generatePartialDependenceData.html">generatePartialDependenceData()</a></code>, one variable must be chosen to be used for facetting, and a subplot for each value in the chosen feature’s grid is created, wherein the other feature’s partial dependences within the facetting feature’s value are shown. Note that this type of plot is limited to two features.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.int</span>, facet <span class="op">=</span> <span class="st">"Petal.Length"</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
<p><code>plotPartialDependenceGGVIS()</code> can be used similarly, however, since <code>ggvis</code> currently lacks subplotting/facetting capabilities, the argument <code>interact</code> maps one feature to an interactive sidebar where the user can select a value of one feature.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">plotPartialDependenceGGVIS</span><span class="op">(</span><span class="va">pd.int</span>, interact <span class="op">=</span> <span class="st">"Petal.Length"</span><span class="op">)</span></code></pre></div>
<p>When <code>individual = TRUE</code> each individual conditional expectation curve is plotted.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.ind.regr</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-22-1.png" width="700"></p>
<p>Plotting partial derivative functions works the same as partial dependence. Below are estimates of the derivative of the mean aggregated partial dependence function, and the individual partial dependence functions for a regression and a classification task respectively.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/plotPartialDependence.html">plotPartialDependence</a></span><span class="op">(</span><span class="va">pd.regr.der</span><span class="op">)</span></code></pre></div>
<p><img src="partial_dependence_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Patrick Schratz, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
