<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Nested Resampling â€¢ mlr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/journal/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/all.min.css" integrity="sha256-PbSmjxuVAzJ6FPvNYsrXygfGhNJYyZ2GktDbkMBqQZg=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.1/css/v4-shims.min.css" integrity="sha256-A6jcAdwFD48VMjlI3GDxUd+eCQa7/KWy6G9oe/ovaPA=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<link href="../../extra.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><!-- docsearch --><script src="../../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Nested Resampling">
<meta property="og:description" content="mlr">
<meta property="og:image" content="https://mlr.mlr-org.com/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a href="https://mlr-org.com"><img src="https://raw.githubusercontent.com/mlr-org/mlr3/master/man/figures/logo.png" id="hexlogo" alt="mlr-org"></a>
        <a class="navbar-brand" href="../../index.html">mlr <small>v2.19.0</small></a>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Task</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learner.html">Learner</a>
    </li>
    <li>
      <a href="../../articles/tutorial/train.html">Train</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmarking</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/usecase_regression.html">Use case - Regression</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configureMlr.html">mlr Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection/Filtering</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/over_and_undersampling.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperpar_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Spatial Data</a>
    </li>
    <li>
      <a href="../../articles/tutorial/functional_data.html">Functional Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extending
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/create_learner.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_measure.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Custom Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/example_tasks.html">Integrated Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/measures.html">Integrated Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../articles/tutorial/mlr_publications.html">mlr Publications</a>
    </li>
    <li>
      <a href="https://github.com/mlr-org/mlr-outreach">Talks, Videos and Workshops</a>
    </li>
    <li class="divider">
    <li>
      <a href="https://mlrmbo.mlr-org.com">mlrMBO</a>
    </li>
    <li>
      <a href="https://https://mlrcpo.mlr-org.com">mlrCPO</a>
    </li>
    <li>
      <a href="https://jakob-r.de/mlrHyperopt/index.html">mlrHyperopt</a>
    </li>
    <li>
      <a href="http://openml.github.io/openml-r/">OpenML</a>
    </li>
    <li class="divider">
    <li>
      <a href="../../news/index.html">Changelog</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
        <li>
  <a href="https://github.com/mlr-org/mlr/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">
    <span class="fa fa fa fa-comments"></span>
     
  </a>
</li>
<li>
  <a href="https://stackoverflow.com/questions/tagged/mlr">
    <span class="fab fa-stack-overflow"></span>
     
  </a>
</li>
<li>
  <a href="https://mlr-org.com/">
    <span class="fas fa-rss"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right docsearch" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="nested_resampling_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Nested Resampling</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr/blob/master/vignettes/tutorial/nested_resampling.Rmd"><code>vignettes/tutorial/nested_resampling.Rmd</code></a></small>
      <div class="hidden name"><code>nested_resampling.Rmd</code></div>

    </div>

    
    
<p>In order to obtain honest performance estimates for a learner all parts of the model building like preprocessing and model selection steps should be included in the resampling, i.e., repeated for every pair of training/test data. For steps that themselves require resampling like parameter <a href="tune.html" target="_blank">tuning</a> or <a href="feature_selection.html" target="_blank">feature selection</a> (via the wrapper approach) this results in two nested resampling loops.</p>
<div class="figure" style="text-align: center">
<img src="../pdf/img/nested_resampling.png" alt="Nested Resampling Figure" width="600px"><p class="caption">
Nested Resampling Figure
</p>
</div>
<p>The graphic above illustrates nested resampling for parameter tuning with 3-fold cross-validation in the outer and 4-fold cross-validation in the inner loop.</p>
<p>In the outer resampling loop, we have three pairs of training/test sets. On each of these outer training sets parameter tuning is done, thereby executing the inner resampling loop. This way, we get one set of selected hyperparameters for each outer training set. Then the learner is fitted on each outer training set using the corresponding selected hyperparameters and its performance is evaluated on the outer test sets.</p>
<p>In <code>mlr</code>, you can get nested resampling for free without programming any looping by using the <a href="wrapper.html" target="_blank">wrapper functionality</a>. This works as follows:</p>
<ol style="list-style-type: decimal">
<li>Generate a wrapped Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) via function <code><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper()</a></code> or <code><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper()</a></code>. Specify the inner resampling strategy using their <code>resampling</code> argument.</li>
<li>Call function <code><a href="../../reference/resample.html">resample()</a></code> (see also the section about <a href="resample.html" target="_blank">resampling</a> and pass the outer resampling strategy to its <code>resampling</code> argument.</li>
</ol>
<p>You can freely combine different inner and outer resampling strategies.</p>
<p>The outer strategy can be a resample description <code>ResampleDesc</code> (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>)) or a resample instance (<code><a href="../../reference/makeResampleInstance.html">makeResampleInstance()</a></code>)). A common setup is prediction and performance evaluation on a fixed outer test set. This can be achieved by using function <code><a href="../../reference/makeFixedHoldoutInstance.html">makeFixedHoldoutInstance()</a></code> to generate the outer resample instance<code>(</code>makeResampleInstance()`).</p>
<p>The inner resampling strategy should preferably be a <code>ResampleDesc</code> (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>), as the sizes of the outer training sets might differ. Per default, the inner resample description is instantiated once for every outer training set. This way during tuning/feature selection all parameter or feature sets are compared on the same inner training/test sets to reduce variance. You can also turn this off using the <code>same.resampling.instance</code> argument of <code>makeTuneControl*</code> (<code><a href="../../reference/TuneControl.html">TuneControl()</a></code>) or <code>makeFeatSelControl*</code> (<code><a href="../../reference/FeatSelControl.html">FeatSelControl()</a></code>).</p>
<p>Nested resampling is computationally expensive. For this reason in the examples shown below we use relatively small search spaces and a low number of resampling iterations. In practice, you normally have to increase both. As this is computationally intensive you might want to have a look at section <a href="parallelization.html" target="_blank">parallelization</a>.</p>
<div id="tuning" class="section level1">
<h1 class="hasAnchor">
<a href="#tuning" class="anchor"></a>Tuning</h1>
<p>As you might recall from the tutorial page about <a href="tune.html" target="_blank">tuning</a>, you need to define a search space by function <code><a href="https://paramhelpers.mlr-org.com/reference/makeParamSet.html">ParamHelpers::makeParamSet()</a></code>, a search strategy by <code>makeTuneControl*</code>(<code><a href="../../reference/TuneControl.html">TuneControl()</a></code>), and a method to evaluate hyperparameter settings (i.e., the inner resampling strategy and a performance measure).</p>
<p>Below is a classification example. We evaluate the performance of a support vector machine (<code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code>) with tuned cost parameter <code>C</code> and RBF kernel parameter <code>sigma</code>. We use 3-fold cross-validation in the outer and subsampling with 2 iterations in the inner loop. For tuing a grid search is used to find the hyperparameters with lowest error rate (<a href="measures.html" target="_blank">mmce</a> is the default measure for classification). The wrapped Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) is generated by calling <code><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper()</a></code>.</p>
<p>Note that in practice the parameter set should be larger. A common recommendation is <code>2^(-12:12)</code> for both <code>C</code> and <code>sigma</code>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Tuning in inner resampling loop</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"C"</span>, values <span class="op">=</span> <span class="fl">2</span><span class="op">^</span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"sigma"</span>, values <span class="op">=</span> <span class="fl">2</span><span class="op">^</span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>, resampling <span class="op">=</span> <span class="va">inner</span>, par.set <span class="op">=</span> <span class="va">ps</span>, control <span class="op">=</span> <span class="va">ctrl</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">r</span> <span class="op">=</span> <span class="fu"><a href="../../reference/resample.html">resample</a></span><span class="op">(</span><span class="va">lrn</span>, <span class="va">iris.task</span>, resampling <span class="op">=</span> <span class="va">outer</span>, extract <span class="op">=</span> <span class="va">getTuneResult</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="va">r</span>

<span class="co">## Resample Result</span>
<span class="co">## Task: iris-example</span>
<span class="co">## Learner: classif.ksvm.tuned</span>
<span class="co">## Aggr perf: mmce.test.mean=0.0400000</span>
<span class="co">## Runtime: 5.50584</span></code></pre></div>
<p>You can obtain the error rates on the 3 outer test sets by:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">r</span><span class="op">$</span><span class="va">measures.test</span>
<span class="co">##   iter mmce</span>
<span class="co">## 1    1 0.06</span>
<span class="co">## 2    2 0.04</span>
<span class="co">## 3    3 0.02</span></code></pre></div>
<div id="accessing-the-tuning-result" class="section level2">
<h2 class="hasAnchor">
<a href="#accessing-the-tuning-result" class="anchor"></a>Accessing the tuning result</h2>
<p>We have kept the results of the tuning for further evaluations. For example one might want to find out, if the best obtained configurations vary for the different outer splits. As storing entire models may be expensive (but possible by setting <code>models = TRUE</code>) we used the <code>extract</code> option of <code><a href="../../reference/resample.html">resample()</a></code>. Function <code><a href="../../reference/getTuneResult.html">getTuneResult()</a></code> returns, among other things, the optimal hyperparameter values and the optimization path (<code><a href="https://paramhelpers.mlr-org.com/reference/OptPath.html">ParamHelpers::OptPath()</a></code>) for each iteration of the outer resampling loop. Note that the performance values shown when printing <code>r$extract</code> are the aggregated performances resulting from inner resampling on the outer training set for the best hyperparameter configurations (not to be confused with <code>r$measures.test</code> shown above).</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">r</span><span class="op">$</span><span class="va">extract</span>
<span class="co">## [[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=1; sigma=0.5</span>
<span class="co">## mmce.test.mean=0.0294118</span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=2; sigma=0.25</span>
<span class="co">## mmce.test.mean=0.0294118</span>
<span class="co">## </span>
<span class="co">## [[3]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=2; sigma=0.25</span>
<span class="co">## mmce.test.mean=0.0147059</span>

<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">extract</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co">## [1] "learner"    "control"    "x"          "y"          "resampling"</span>
<span class="co">## [6] "threshold"  "opt.path"</span></code></pre></div>
<p>We can compare the optimal parameter settings obtained in the 3 resampling iterations. As you can see, the optimal configuration usually depends on the data. You may be able to identify a <em>range</em> of parameter settings that achieve good performance though, e.g., the values for <code>C</code> should be at least 1 and the values for <code>sigma</code> should be between 0 and 1.</p>
<p>With function <code><a href="../../reference/getNestedTuneResultsOptPathDf.html">getNestedTuneResultsOptPathDf()</a></code> you can extract the optimization paths for the 3 outer cross-validation iterations for further inspection and analysis. These are stacked in one <code>data.frame</code> with column <code>iter</code> indicating the resampling iteration.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">opt.paths</span> <span class="op">=</span> <span class="fu"><a href="../../reference/getNestedTuneResultsOptPathDf.html">getNestedTuneResultsOptPathDf</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">opt.paths</span>, <span class="fl">10</span><span class="op">)</span>

<span class="co">##       C sigma mmce.test.mean dob eol error.message exec.time iter</span>
<span class="co">## 1  0.25  0.25     0.10294118   1  NA          &lt;NA&gt;     1.463    1</span>
<span class="co">## 2   0.5  0.25     0.11764706   2  NA          &lt;NA&gt;     0.036    1</span>
<span class="co">## 3     1  0.25     0.07352941   3  NA          &lt;NA&gt;     0.043    1</span>
<span class="co">## 4     2  0.25     0.07352941   4  NA          &lt;NA&gt;     0.040    1</span>
<span class="co">## 5     4  0.25     0.08823529   5  NA          &lt;NA&gt;     0.042    1</span>
<span class="co">## 6  0.25   0.5     0.13235294   6  NA          &lt;NA&gt;     0.041    1</span>
<span class="co">## 7   0.5   0.5     0.07352941   7  NA          &lt;NA&gt;     0.043    1</span>
<span class="co">## 8     1   0.5     0.07352941   8  NA          &lt;NA&gt;     0.042    1</span>
<span class="co">## 9     2   0.5     0.07352941   9  NA          &lt;NA&gt;     0.037    1</span>
<span class="co">## 10    4   0.5     0.10294118  10  NA          &lt;NA&gt;     0.042    1</span></code></pre></div>
<p>Below we visualize the <code>opt.path</code>s for the 3 outer resampling iterations.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">g</span> <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">opt.paths</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">C</span>, y <span class="op">=</span> <span class="va">sigma</span>, fill <span class="op">=</span> <span class="va">mmce.test.mean</span><span class="op">)</span><span class="op">)</span>
<span class="va">g</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_tile</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">iter</span><span class="op">)</span></code></pre></div>
<p><img src="nested_resampling_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
<p>Another useful function is <code><a href="../../reference/getNestedTuneResultsX.html">getNestedTuneResultsX()</a></code>, which extracts the best found hyperparameter settings for each outer resampling iteration.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getNestedTuneResultsX.html">getNestedTuneResultsX</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span>
<span class="co">##   C sigma</span>
<span class="co">## 1 1  0.50</span>
<span class="co">## 2 2  0.25</span>
<span class="co">## 3 2  0.25</span></code></pre></div>
<p>You can furthermore access the resampling indices of the inner level using <code><a href="../../reference/getResamplingIndices.html">getResamplingIndices()</a></code> if you used either <code>extract = getTuneResult</code> or <code>extract = getFeatSelResult</code> in the <code><a href="../../reference/resample.html">resample()</a></code> call:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getResamplingIndices.html">getResamplingIndices</a></span><span class="op">(</span><span class="va">r</span>, inner <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">## [[1]]</span>
<span class="co">## [[1]]$train.inds</span>
<span class="co">## [[1]]$train.inds[[1]]</span>
<span class="co">##  [1] 122 139 148  93  60  28 146 141 126   1  38 117  10 124 129  34 101  36  91</span>
<span class="co">## [20]   2  99  33  42  61  51  87  96  54   7 132 115 113  32 150  41  40  64  69</span>
<span class="co">## [39]  12 110 112 106  31  78 109 102   9  44  84 104  56 147  86 130 123 105 125</span>
<span class="co">## [58]  70 133 135 142  58 128 111  16  55</span>
<span class="co">## </span>
<span class="co">## [[1]]$train.inds[[2]]</span>
<span class="co">##  [1]  36 136 118  93 123   2 117  75  33 109  98  62 116 144  56 150  28   1  82</span>
<span class="co">## [20] 115  20  86 125  29  14  44  11  17  54 133  91  60  18  99  73 104  37 132</span>
<span class="co">## [39]   9   7  61  68  87  65 106  50 130 147  16  38 114 139  12 145  70 124 134</span>
<span class="co">## [58] 146  58  42  55  31  74  77  26 148</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## [[1]]$test.inds</span>
<span class="co">## [[1]]$test.inds[[1]]</span>
<span class="co">##  [1]  73  20  90  13  80  68  77  14  26 145  11  37 118 103 116  62 134  29  27</span>
<span class="co">## [20]  98  65  30  18 100  82 144  22  50  74  17   5  75 114 136</span>
<span class="co">## </span>
<span class="co">## [[1]]$test.inds[[2]]</span>
<span class="co">##  [1] 141  69  90  41  34 112  13  80 103  84  32 110 142  27 122  30 135 113 102</span>
<span class="co">## [20] 100 128  96  10 101 126 111  51  22  64 105   5  40  78 129</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">## [[2]]$train.inds</span>
<span class="co">## [[2]]$train.inds[[1]]</span>
<span class="co">##  [1] 143  56 119 108  48  49  85  43 120  24 135 146 149 114  12 133  40  36   6</span>
<span class="co">## [20]  33 107  13 128  31  73 127  46 140  59  41  51  35 100  72   7  53  44  77</span>
<span class="co">## [39] 150  20 105  74  90 118  52  92  79 137   3  57  16 121  87  45  76  80  30</span>
<span class="co">## [58]  94  26  95  15  63 126  89  67 124</span>
<span class="co">## </span>
<span class="co">## [[2]]$train.inds[[2]]</span>
<span class="co">##  [1]  59 111   3  48  76  16 140 149   8   5 128  94  20  79  87  42  85  83  35</span>
<span class="co">## [20] 138  62  56  21  44 121  25 135  18 144 114  45  89 127  36  88  81 101  92</span>
<span class="co">## [39]  73  39 145  61  24 150  90  51  13   4 108  70  26 104 119 146 129  46  77</span>
<span class="co">## [58]  17 133  97  23 107 120  63 143 118</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## [[2]]$test.inds</span>
<span class="co">## [[2]]$test.inds[[1]]</span>
<span class="co">##  [1]   5  17  19  18  55  61  25  47   4 131 129 101 144  88  81  99  62  70 145</span>
<span class="co">## [20]  50 111  23  21  39  97  58  42  71 104  66 138  78   8  83</span>
<span class="co">## </span>
<span class="co">## [[2]]$test.inds[[2]]</span>
<span class="co">##  [1] 126 100  19  15  55  40  43  47  74 105   7 131 124  49  12  53  99  33   6</span>
<span class="co">## [20]  50  41  52  58  67  31  71  66  57  78  95  72  80 137  30</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## [[3]]</span>
<span class="co">## [[3]]$train.inds</span>
<span class="co">## [[3]]$train.inds[[1]]</span>
<span class="co">##  [1]  63  45  10  75  69 113 106  92   1  29  89  47 142  81 122   6  65  25  71</span>
<span class="co">## [20]  53  60 120  93 136   9 143 110  48  79  86  19   3  57  24  67 123  66 131</span>
<span class="co">## [39] 127 140  23   2  85  72  76  39  46 119  82 138 130 149   8  35 116 125  14</span>
<span class="co">## [58]  34 117  15  64   4  98  27 148 103</span>
<span class="co">## </span>
<span class="co">## [[3]]$train.inds[[2]]</span>
<span class="co">##  [1] 125 140 119 147  84  79  96  47  69  93   3  91 131  95  43  35 134 110  45</span>
<span class="co">## [20]  85  60  27  53 103   6 137  49  67 115  83 116  76  25  64 149  97   8  52</span>
<span class="co">## [39]  34  89  28   1  66  21  19  29  11  32 112   9 120   4 108 102  10 127 117</span>
<span class="co">## [58] 138 113  75 141 143  39  59  22 132</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## [[3]]$test.inds</span>
<span class="co">## [[3]]$test.inds[[1]]</span>
<span class="co">##  [1]  52  37  88  22 109  95 102  84 132  83 134 141 115 121 108  54  94 112  32</span>
<span class="co">## [20]  38  43 139 147  49  28  59  21  97  68 107  91 137  96  11</span>
<span class="co">## </span>
<span class="co">## [[3]]$test.inds[[2]]</span>
<span class="co">##  [1] 130 122  14  37  63  92  82  88 109  57  24  71  72 121  81 142  54  46  94</span>
<span class="co">## [20]  98  48  38  23 139  86   2 148  15  68 107 136 123 106  65</span></code></pre></div>
</div>
</div>
<div id="feature-selection" class="section level1">
<h1 class="hasAnchor">
<a href="#feature-selection" class="anchor"></a>Feature selection</h1>
<p>As you might recall from the section about <a href="feature_selection.html" target="_blank">feature selection</a>, <code>mlr</code> supports the filter and the wrapper approach.</p>
<div id="wrapper-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#wrapper-methods" class="anchor"></a>Wrapper methods</h2>
<p>Wrapper methods use the performance of a learning algorithm to assess the usefulness of a feature set. In order to select a feature subset a learner is trained repeatedly on different feature subsets and the subset which leads to the best learner performance is chosen.</p>
<p>For feature selection in the inner resampling loop, you need to choose a search strategy (function <code>makeFeatSelControl*</code> (<code><a href="../../reference/FeatSelControl.html">FeatSelControl()</a></code>)), a performance measure and the inner resampling strategy. Then use function <code><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper()</a></code> to bind everything together.</p>
<p>Below we use sequential forward selection with linear regression on the <code>BostonHousing</code> (<code><a href="https://rdrr.io/pkg/mlbench/man/BostonHousing.html">mlbench::BostonHousing()</a></code> data set (<code><a href="../../reference/bh.task.html">bh.task()</a></code>).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Feature selection in inner resampling loop</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper</a></span><span class="op">(</span><span class="st">"regr.lm"</span>,
  resampling <span class="op">=</span> <span class="va">inner</span>,
  control <span class="op">=</span> <span class="fu"><a href="../../reference/FeatSelControl.html">makeFeatSelControlSequential</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"sfs"</span><span class="op">)</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">r</span> <span class="op">=</span> <span class="fu"><a href="../../reference/resample.html">resample</a></span><span class="op">(</span>
  learner <span class="op">=</span> <span class="va">lrn</span>, task <span class="op">=</span> <span class="va">bh.task</span>, resampling <span class="op">=</span> <span class="va">outer</span>, extract <span class="op">=</span> <span class="va">getFeatSelResult</span>,
  show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="va">r</span>

<span class="co">## Resample Result</span>
<span class="co">## Task: BostonHousing-example</span>
<span class="co">## Learner: regr.lm.featsel</span>
<span class="co">## Aggr perf: mse.test.mean=24.8753005</span>
<span class="co">## Runtime: 7.01506</span>

<span class="va">r</span><span class="op">$</span><span class="va">measures.test</span>

<span class="co">##   iter      mse</span>
<span class="co">## 1    1 22.28967</span>
<span class="co">## 2    2 27.46093</span></code></pre></div>
<div id="accessing-the-selected-features" class="section level3">
<h3 class="hasAnchor">
<a href="#accessing-the-selected-features" class="anchor"></a>Accessing the selected features</h3>
<p>The result of the feature selection can be extracted by function <code><a href="../../reference/getFeatSelResult.html">getFeatSelResult()</a></code>. It is also possible to keep whole models (<code><a href="../../reference/makeWrappedModel.html">makeWrappedModel()</a></code>) by setting <code>models = TRUE</code> when calling <code><a href="../../reference/resample.html">resample()</a></code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">r</span><span class="op">$</span><span class="va">extract</span>
<span class="co">## [[1]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (8): zn, chas, nox, rm, dis, ptratio, b, lstat</span>
<span class="co">## mse.test.mean=26.8943900</span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (10): crim, zn, nox, rm, dis, rad, tax, ptratio, b, l...</span>
<span class="co">## mse.test.mean=21.5240684</span>

<span class="co"># Selected features in the first outer resampling iteration</span>
<span class="va">r</span><span class="op">$</span><span class="va">extract</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">x</span>
<span class="co">## [1] "zn"      "chas"    "nox"     "rm"      "dis"     "ptratio" "b"      </span>
<span class="co">## [8] "lstat"</span>

<span class="co"># Resampled performance of the selected feature subset on the first inner training set</span>
<span class="va">r</span><span class="op">$</span><span class="va">extract</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">y</span>
<span class="co">## mse.test.mean </span>
<span class="co">##      26.89439</span></code></pre></div>
<p>As for tuning, you can extract the optimization paths. The resulting <code>data.frame</code>s contain, among others, binary columns for all features, indicating if they were included in the linear regression model, and the corresponding performances.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">opt.paths</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">extract</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">opt.path</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">opt.paths</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>

<span class="co">##   crim zn indus chas nox rm age dis rad tax ptratio b lstat mse.test.mean</span>
<span class="co">## 1    0  0     0    0   0  0   0   0   0   0       0 0     0      84.52018</span>
<span class="co">## 2    1  0     0    0   0  0   0   0   0   0       0 0     0      95.46348</span>
<span class="co">## 3    0  1     0    0   0  0   0   0   0   0       0 0     0      74.97858</span>
<span class="co">## 4    0  0     1    0   0  0   0   0   0   0       0 0     0      66.35546</span>
<span class="co">## 5    0  0     0    1   0  0   0   0   0   0       0 0     0      81.49228</span>
<span class="co">## 6    0  0     0    0   1  0   0   0   0   0       0 0     0      67.72664</span>
<span class="co">##   dob eol error.message exec.time</span>
<span class="co">## 1   1   2          &lt;NA&gt;     0.031</span>
<span class="co">## 2   2   2          &lt;NA&gt;     0.037</span>
<span class="co">## 3   2   2          &lt;NA&gt;     0.027</span>
<span class="co">## 4   2   2          &lt;NA&gt;     0.030</span>
<span class="co">## 5   2   2          &lt;NA&gt;     0.032</span>
<span class="co">## 6   2   2          &lt;NA&gt;     0.031</span></code></pre></div>
<p>An easy-to-read version of the optimization path for sequential feature selection can be obtained with function <code><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult()</a></code>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">extract</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co">## Features         : 8</span>
<span class="co">## Performance      : mse.test.mean=26.8943900</span>
<span class="co">## zn, chas, nox, rm, dis, ptratio, b, lstat</span>
<span class="co">## </span>
<span class="co">## Path to optimum:</span>
<span class="co">## - Features:    0  Init   :                       Perf = 91.377  Diff: NA  *</span>
<span class="co">## - Features:    1  Add    : lstat                 Perf = 40.871  Diff: 50.506  *</span>
<span class="co">## - Features:    2  Add    : rm                    Perf = 34.606  Diff: 6.265  *</span>
<span class="co">## - Features:    3  Add    : ptratio               Perf = 31.673  Diff: 2.9328  *</span>
<span class="co">## - Features:    4  Add    : dis                   Perf = 30.535  Diff: 1.1381  *</span>
<span class="co">## - Features:    5  Add    : nox                   Perf = 28.968  Diff: 1.5667  *</span>
<span class="co">## - Features:    6  Add    : zn                    Perf = 27.993  Diff: 0.97562  *</span>
<span class="co">## - Features:    7  Add    : b                     Perf = 27.253  Diff: 0.73917  *</span>
<span class="co">## - Features:    8  Add    : chas                  Perf = 26.894  Diff: 0.35905  *</span>
<span class="co">## </span>
<span class="co">## Stopped, because no improving feature was found.</span></code></pre></div>
</div>
</div>
<div id="filter-methods-with-tuning" class="section level2">
<h2 class="hasAnchor">
<a href="#filter-methods-with-tuning" class="anchor"></a>Filter methods with tuning</h2>
<p>Filter methods assign an importance value to each feature. Based on these values you can select a feature subset by either keeping all features with importance higher than a certain threshold or by keeping a fixed number or percentage of the highest ranking features. Often, neither the theshold nor the number or percentage of features is known in advance and thus tuning is necessary.</p>
<p>In the example below the threshold value (<code>fw.threshold</code>) is tuned in the inner resampling loop. For this purpose the base Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>) <code>"regr.lm"</code> is wrapped two times. First, <code><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper()</a></code> is used to fuse linear regression with a feature filtering preprocessing step. Then a tuning step is added by <code><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper()</a></code>.</p>
<pre><code>## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.

## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =
## equal, : Dependent variable is a numeric! It will be converted to factor with
## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by
## default! You can choose equal frequency binning discretization by setting equal
## argument to TRUE.</code></pre>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Tuning of the percentage of selected filters in the inner loop</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper</a></span><span class="op">(</span>learner <span class="op">=</span> <span class="st">"regr.lm"</span>, fw.method <span class="op">=</span> <span class="st">"FSelectorRcpp_information.gain"</span><span class="op">)</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span><span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"fw.threshold"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper</a></span><span class="op">(</span><span class="va">lrn</span>, resampling <span class="op">=</span> <span class="va">inner</span>, par.set <span class="op">=</span> <span class="va">ps</span>, control <span class="op">=</span> <span class="va">ctrl</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iters <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">r</span> <span class="op">=</span> <span class="fu"><a href="../../reference/resample.html">resample</a></span><span class="op">(</span>learner <span class="op">=</span> <span class="va">lrn</span>, task <span class="op">=</span> <span class="va">bh.task</span>, resampling <span class="op">=</span> <span class="va">outer</span>, models <span class="op">=</span> <span class="cn">TRUE</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">r</span>

<span class="co">## Resample Result</span>
<span class="co">## Task: BostonHousing-example</span>
<span class="co">## Learner: regr.lm.filtered.tuned</span>
<span class="co">## Aggr perf: mse.test.mean=23.5449481</span>
<span class="co">## Runtime: 3.85235</span></code></pre></div>
<div id="accessing-the-selected-features-and-optimal-percentage" class="section level3">
<h3 class="hasAnchor">
<a href="#accessing-the-selected-features-and-optimal-percentage" class="anchor"></a>Accessing the selected features and optimal percentage</h3>
<p>In the above example we kept the complete model (<code><a href="../../reference/makeWrappedModel.html">makeWrappedModel()</a></code>)s.</p>
<p>Below are some examples that show how to extract information from the model (<code><a href="../../reference/makeWrappedModel.html">makeWrappedModel()</a></code>)s.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">r</span><span class="op">$</span><span class="va">models</span>
<span class="co">## [[1]]</span>
<span class="co">## Model for learner.id=regr.lm.filtered.tuned; learner.class=TuneWrapper</span>
<span class="co">## Trained on: task.id = BostonHousing-example; obs = 337; features = 13</span>
<span class="co">## Hyperparameters: fw.method=FSelectorRcp...</span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">## Model for learner.id=regr.lm.filtered.tuned; learner.class=TuneWrapper</span>
<span class="co">## Trained on: task.id = BostonHousing-example; obs = 337; features = 13</span>
<span class="co">## Hyperparameters: fw.method=FSelectorRcp...</span>
<span class="co">## </span>
<span class="co">## [[3]]</span>
<span class="co">## Model for learner.id=regr.lm.filtered.tuned; learner.class=TuneWrapper</span>
<span class="co">## Trained on: task.id = BostonHousing-example; obs = 338; features = 13</span>
<span class="co">## Hyperparameters: fw.method=FSelectorRcp...</span></code></pre></div>
<p>The result of the feature selection can be extracted by function <code><a href="../../reference/getFilteredFeatures.html">getFilteredFeatures()</a></code>. Almost always all 13 features are selected.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">models</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="../../reference/getFilteredFeatures.html">getFilteredFeatures</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">learner.model</span><span class="op">$</span><span class="va">next.model</span><span class="op">)</span><span class="op">)</span>
<span class="co">## [[1]]</span>
<span class="co">##  [1] "crim"    "zn"      "indus"   "chas"    "nox"     "rm"      "age"    </span>
<span class="co">##  [8] "dis"     "rad"     "tax"     "ptratio" "b"       "lstat"  </span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">##  [1] "crim"    "zn"      "indus"   "chas"    "nox"     "rm"      "age"    </span>
<span class="co">##  [8] "dis"     "rad"     "tax"     "ptratio" "b"       "lstat"  </span>
<span class="co">## </span>
<span class="co">## [[3]]</span>
<span class="co">##  [1] "crim"    "zn"      "indus"   "chas"    "nox"     "rm"      "age"    </span>
<span class="co">##  [8] "dis"     "rad"     "tax"     "ptratio" "b"       "lstat"</span></code></pre></div>
<p>Below the tune results (<code><a href="../../reference/TuneResult.html">TuneResult()</a></code>) and optimization paths (<code><a href="https://paramhelpers.mlr-org.com/reference/OptPath.html">ParamHelpers::OptPath()</a></code>) are accessed.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">models</span>, <span class="va">getTuneResult</span><span class="op">)</span>
<span class="va">res</span>
<span class="co">## [[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: fw.threshold=0</span>
<span class="co">## mse.test.mean=24.0256189</span>
<span class="co">## </span>
<span class="co">## [[2]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: fw.threshold=0</span>
<span class="co">## mse.test.mean=22.3639004</span>
<span class="co">## </span>
<span class="co">## [[3]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: fw.threshold=0</span>
<span class="co">## mse.test.mean=25.7198156</span>

<span class="va">opt.paths</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">res</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">opt.path</span><span class="op">)</span><span class="op">)</span>
<span class="va">opt.paths</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">opt.paths</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">]</span>
<span class="co">##   fw.threshold mse.test.mean dob eol error.message</span>
<span class="co">## 1            0      24.02562   1  NA          &lt;NA&gt;</span>
<span class="co">## 2          0.2      67.30442   2  NA          &lt;NA&gt;</span>
<span class="co">## 3          0.4      67.82551   3  NA          &lt;NA&gt;</span>
<span class="co">## 4          0.6      67.82551   4  NA          &lt;NA&gt;</span>
<span class="co">## 5          0.8      67.82551   5  NA          &lt;NA&gt;</span>
<span class="co">## 6            1      67.82551   6  NA          &lt;NA&gt;</span></code></pre></div>
</div>
</div>
</div>
<div id="benchmark-experiments" class="section level1">
<h1 class="hasAnchor">
<a href="#benchmark-experiments" class="anchor"></a>Benchmark experiments</h1>
<p>In a benchmark experiment multiple learners are compared on one or several tasks (see also the section about <a href="benchmark_experiments.html" target="_blank">benchmarking</a>. Nested resampling in benchmark experiments is achieved the same way as in resampling:</p>
<ul>
<li>First, use <code><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper()</a></code> or <code><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper()</a></code> to generate wrapped Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>)s with the inner resampling strategies of your choice.</li>
<li>Second, call <code><a href="../../reference/benchmark.html">benchmark()</a></code> and specify the outer resampling strategies for all tasks.</li>
</ul>
<p>The inner resampling strategies should be resample descriptions (<code><a href="../../reference/makeResampleDesc.html">makeResampleDesc()</a></code>). You can use different inner resampling strategies for different wrapped learners. For example it might be practical to do fewer subsampling or bootstrap iterations for slower learners.</p>
<p>If you have larger benchmark experiments you might want to have a look at the section about <a href="parallelization.html" target="_blank">parallelization</a>.</p>
<p>As mentioned in the section about <a href="benchmark_experiments.html" target="_blank">benchmark experiments</a> you can also use different resampling strategies for different learning tasks by passing a <code>list</code> of resampling descriptions or instances to <code><a href="../../reference/benchmark.html">benchmark()</a></code>.</p>
<p>We will see three examples to show different benchmark settings:</p>
<ol style="list-style-type: decimal">
<li>Two data sets + two classification algorithms + tuning</li>
<li>One data set + two regression algorithms + feature selection</li>
<li>One data set + two regression algorithms + feature filtering + tuning</li>
</ol>
<div id="example-1-two-tasks-two-learners-tuning" class="section level2">
<h2 class="hasAnchor">
<a href="#example-1-two-tasks-two-learners-tuning" class="anchor"></a>Example 1: Two tasks, two learners, tuning</h2>
<p>Below is a benchmark experiment with two data sets, <code><a href="https://rdrr.io/r/datasets/iris.html">datasets::iris()</a></code> and <code>mlbench::sonar()</code>, and two Learner (<code><a href="../../reference/makeLearner.html">makeLearner()</a></code>)s, <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code> and <code><a href="https://rdrr.io/pkg/kknn/man/kknn.html">kknn::kknn()</a></code>, that are both tuned.</p>
<p>As inner resampling strategies we use holdout for <code><a href="https://rdrr.io/pkg/kernlab/man/ksvm.html">kernlab::ksvm()</a></code> and subsampling with 3 iterations for <code><a href="https://rdrr.io/pkg/kknn/man/kknn.html">kknn::kknn()</a></code>. As outer resampling strategies we take holdout for the <code><a href="https://rdrr.io/r/datasets/iris.html">datasets::iris()</a></code> and bootstrap with 2 iterations for the <code>mlbench::sonar()</code> data (<code><a href="../../reference/sonar.task.html">sonar.task()</a></code>). We consider the accuracy (<a href="measures.html" target="_blank">acc</a>), which is used as tuning criterion, and also calculate the balanced error rate (<a href="measures.html" target="_blank">ber</a>).</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># List of learning tasks</span>
<span class="va">tasks</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">iris.task</span>, <span class="va">sonar.task</span><span class="op">)</span>

<span class="co"># Tune svm in the inner resampling loop</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span>
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"C"</span>, <span class="fl">2</span><span class="op">^</span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"sigma"</span>, <span class="fl">2</span><span class="op">^</span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Holdout"</span><span class="op">)</span>
<span class="va">lrn1</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper</a></span><span class="op">(</span><span class="st">"classif.ksvm"</span>,
  resampling <span class="op">=</span> <span class="va">inner</span>, par.set <span class="op">=</span> <span class="va">ps</span>, control <span class="op">=</span> <span class="va">ctrl</span>,
  show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Tune k-nearest neighbor in inner resampling loop</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span><span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"k"</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iters <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">lrn2</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper</a></span><span class="op">(</span><span class="st">"classif.kknn"</span>,
  resampling <span class="op">=</span> <span class="va">inner</span>, par.set <span class="op">=</span> <span class="va">ps</span>, control <span class="op">=</span> <span class="va">ctrl</span>,
  show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">## Loading required package: kknn</span>

<span class="co"># Learners</span>
<span class="va">lrns</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">lrn1</span>, <span class="va">lrn2</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Holdout"</span><span class="op">)</span>, <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Bootstrap"</span>, iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">lrns</span>, <span class="va">tasks</span>, <span class="va">outer</span>,
  measures <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="va">acc</span>, <span class="va">ber</span><span class="op">)</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span>,
  keep.extract <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">res</span>
<span class="co">##         task.id         learner.id acc.test.mean ber.test.mean</span>
<span class="co">## 1  iris-example classif.ksvm.tuned     0.9800000    0.02222222</span>
<span class="co">## 2  iris-example classif.kknn.tuned     0.9600000    0.04305556</span>
<span class="co">## 3 Sonar-example classif.ksvm.tuned     0.4903819    0.50000000</span>
<span class="co">## 4 Sonar-example classif.kknn.tuned     0.8725237    0.12827855</span></code></pre></div>
<p>The <code>print</code> method for the <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> shows the aggregated performances from the outer resampling loop.</p>
<p>As you might recall, <code>mlr</code> offers several accessor function to extract information from the benchmark result. These are listed on the help page of <code><a href="../../reference/BenchmarkResult.html">BenchmarkResult()</a></code> and many examples are shown on the tutorial page about <a href="benchmark_experiments.html" target="_blank">benchmark experiments</a>.</p>
<p>The performance values in individual outer resampling runs can be obtained by <code><a href="../../reference/getBMRPerformances.html">getBMRPerformances()</a></code>. Note that, since we used different outer resampling strategies for the two tasks, the number of rows per task differ.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span><span class="op">(</span><span class="va">res</span>, as.df <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">##         task.id         learner.id iter       acc        ber</span>
<span class="co">## 1  iris-example classif.ksvm.tuned    1 0.9800000 0.02222222</span>
<span class="co">## 2  iris-example classif.kknn.tuned    1 0.9600000 0.04305556</span>
<span class="co">## 3 Sonar-example classif.ksvm.tuned    1 0.5116279 0.50000000</span>
<span class="co">## 4 Sonar-example classif.ksvm.tuned    2 0.4691358 0.50000000</span>
<span class="co">## 5 Sonar-example classif.kknn.tuned    1 0.9302326 0.07142857</span>
<span class="co">## 6 Sonar-example classif.kknn.tuned    2 0.8148148 0.18512852</span></code></pre></div>
<p>The results from the parameter tuning can be obtained through function <code><a href="../../reference/getBMRTuneResults.html">getBMRTuneResults()</a></code>.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getBMRTuneResults.html">getBMRTuneResults</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>
<span class="co">## $`iris-example`</span>
<span class="co">## $`iris-example`$classif.ksvm.tuned</span>
<span class="co">## $`iris-example`$classif.ksvm.tuned[[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=2; sigma=0.5</span>
<span class="co">## mmce.test.mean=0.0294118</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $`iris-example`$classif.kknn.tuned</span>
<span class="co">## $`iris-example`$classif.kknn.tuned[[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: k=5</span>
<span class="co">## mmce.test.mean=0.0392157</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`</span>
<span class="co">## $`Sonar-example`$classif.ksvm.tuned</span>
<span class="co">## $`Sonar-example`$classif.ksvm.tuned[[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=1; sigma=2</span>
<span class="co">## mmce.test.mean=0.2285714</span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.ksvm.tuned[[2]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: C=0.5; sigma=0.5</span>
<span class="co">## mmce.test.mean=0.2714286</span>
<span class="co">## </span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.kknn.tuned</span>
<span class="co">## $`Sonar-example`$classif.kknn.tuned[[1]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: k=5</span>
<span class="co">## mmce.test.mean=0.0714286</span>
<span class="co">## </span>
<span class="co">## $`Sonar-example`$classif.kknn.tuned[[2]]</span>
<span class="co">## Tune result:</span>
<span class="co">## Op. pars: k=4</span>
<span class="co">## mmce.test.mean=0.0666667</span></code></pre></div>
<p>As for several other accessor functions a clearer representation as <code>data.frame</code> can be achieved by setting <code>as.df = TRUE</code>.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getBMRTuneResults.html">getBMRTuneResults</a></span><span class="op">(</span><span class="va">res</span>, as.df <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">##         task.id         learner.id iter   C sigma mmce.test.mean  k</span>
<span class="co">## 1  iris-example classif.ksvm.tuned    1 2.0   0.5     0.02941176 NA</span>
<span class="co">## 2  iris-example classif.kknn.tuned    1  NA    NA     0.03921569  5</span>
<span class="co">## 3 Sonar-example classif.ksvm.tuned    1 1.0   2.0     0.22857143 NA</span>
<span class="co">## 4 Sonar-example classif.ksvm.tuned    2 0.5   0.5     0.27142857 NA</span>
<span class="co">## 5 Sonar-example classif.kknn.tuned    1  NA    NA     0.07142857  5</span>
<span class="co">## 6 Sonar-example classif.kknn.tuned    2  NA    NA     0.06666667  4</span></code></pre></div>
<p>It is also possible to extract the tuning results for individual tasks and learners and, as shown in earlier examples, inspect the optimization path (<code><a href="https://paramhelpers.mlr-org.com/reference/OptPath.html">ParamHelpers::OptPath()</a></code>).</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tune.res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/getBMRTuneResults.html">getBMRTuneResults</a></span><span class="op">(</span><span class="va">res</span>,
  task.ids <span class="op">=</span> <span class="st">"Sonar-example"</span>, learner.ids <span class="op">=</span> <span class="st">"classif.ksvm.tuned"</span>,
  as.df <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">tune.res</span>
<span class="co">##         task.id         learner.id iter   C sigma mmce.test.mean</span>
<span class="co">## 1 Sonar-example classif.ksvm.tuned    1 1.0   2.0      0.2285714</span>
<span class="co">## 2 Sonar-example classif.ksvm.tuned    2 0.5   0.5      0.2714286</span>

<span class="fu"><a href="../../reference/getNestedTuneResultsOptPathDf.html">getNestedTuneResultsOptPathDf</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">results</span><span class="op">[[</span><span class="st">"Sonar-example"</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="st">"classif.ksvm.tuned"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co">##      C sigma mmce.test.mean dob eol error.message exec.time iter</span>
<span class="co">## 1  0.5   0.5      0.2285714   1  NA          &lt;NA&gt;     0.031    1</span>
<span class="co">## 2    1   0.5      0.2285714   2  NA          &lt;NA&gt;     0.032    1</span>
<span class="co">## 3    2   0.5      0.2285714   3  NA          &lt;NA&gt;     0.032    1</span>
<span class="co">## 4  0.5     1      0.2285714   4  NA          &lt;NA&gt;     0.033    1</span>
<span class="co">## 5    1     1      0.2285714   5  NA          &lt;NA&gt;     0.033    1</span>
<span class="co">## 6    2     1      0.2285714   6  NA          &lt;NA&gt;     0.034    1</span>
<span class="co">## 7  0.5     2      0.2285714   7  NA          &lt;NA&gt;     0.045    1</span>
<span class="co">## 8    1     2      0.2285714   8  NA          &lt;NA&gt;     0.032    1</span>
<span class="co">## 9    2     2      0.2285714   9  NA          &lt;NA&gt;     0.031    1</span>
<span class="co">## 10 0.5   0.5      0.2714286   1  NA          &lt;NA&gt;     0.033    2</span>
<span class="co">## 11   1   0.5      0.2714286   2  NA          &lt;NA&gt;     0.033    2</span>
<span class="co">## 12   2   0.5      0.2714286   3  NA          &lt;NA&gt;     0.044    2</span>
<span class="co">## 13 0.5     1      0.2714286   4  NA          &lt;NA&gt;     0.032    2</span>
<span class="co">## 14   1     1      0.2714286   5  NA          &lt;NA&gt;     0.032    2</span>
<span class="co">## 15   2     1      0.2714286   6  NA          &lt;NA&gt;     0.032    2</span>
<span class="co">## 16 0.5     2      0.2714286   7  NA          &lt;NA&gt;     0.031    2</span>
<span class="co">## 17   1     2      0.2714286   8  NA          &lt;NA&gt;     0.032    2</span>
<span class="co">## 18   2     2      0.2714286   9  NA          &lt;NA&gt;     0.043    2</span></code></pre></div>
</div>
<div id="example-2-one-task-two-learners-feature-selection" class="section level2">
<h2 class="hasAnchor">
<a href="#example-2-one-task-two-learners-feature-selection" class="anchor"></a>Example 2: One task, two learners, feature selection</h2>
<p>Letâ€™s see how we can do <a href="feature_selection.html" target="_blank">feature selection</a> in a benchmark experiment:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Feature selection in inner resampling loop</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/FeatSelControl.html">makeFeatSelControlSequential</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"sfs"</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeFeatSelWrapper.html">makeFeatSelWrapper</a></span><span class="op">(</span><span class="st">"regr.lm"</span>, resampling <span class="op">=</span> <span class="va">inner</span>, control <span class="op">=</span> <span class="va">ctrl</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Learners</span>
<span class="va">lrns</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"regr.rpart"</span>, <span class="va">lrn</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iters <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span><span class="op">(</span>
  tasks <span class="op">=</span> <span class="va">bh.task</span>, learners <span class="op">=</span> <span class="va">lrns</span>, resampling <span class="op">=</span> <span class="va">outer</span>,
  show.info <span class="op">=</span> <span class="cn">FALSE</span>, keep.extract <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="va">res</span>
<span class="co">##                 task.id      learner.id mse.test.mean</span>
<span class="co">## 1 BostonHousing-example      regr.rpart      23.58119</span>
<span class="co">## 2 BostonHousing-example regr.lm.featsel      24.75507</span></code></pre></div>
<p>The selected features can be extracted by function <code><a href="../../reference/getBMRFeatSelResults.html">getBMRFeatSelResults()</a></code>. By default, a nested <code>list</code>, with the first level indicating the task and the second level indicating the learner, is returned. If only a single learner or, as in our case, a single task is considered, setting <code>drop = TRUE</code> simplifies the result to a flat <code>list</code>.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../../reference/getBMRFeatSelResults.html">getBMRFeatSelResults</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span>
<span class="co">## $`BostonHousing-example`</span>
<span class="co">## $`BostonHousing-example`$regr.rpart</span>
<span class="co">## NULL</span>
<span class="co">## </span>
<span class="co">## $`BostonHousing-example`$regr.lm.featsel</span>
<span class="co">## $`BostonHousing-example`$regr.lm.featsel[[1]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (7): indus, rm, age, dis, ptratio, b, lstat</span>
<span class="co">## mse.test.mean=29.4228023</span>
<span class="co">## </span>
<span class="co">## $`BostonHousing-example`$regr.lm.featsel[[2]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (9): zn, indus, chas, nox, rm, dis, ptratio, b, lstat</span>
<span class="co">## mse.test.mean=26.1964766</span>
<span class="fu"><a href="../../reference/getBMRFeatSelResults.html">getBMRFeatSelResults</a></span><span class="op">(</span><span class="va">res</span>, drop <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">## $regr.rpart</span>
<span class="co">## NULL</span>
<span class="co">## </span>
<span class="co">## $regr.lm.featsel</span>
<span class="co">## $regr.lm.featsel[[1]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (7): indus, rm, age, dis, ptratio, b, lstat</span>
<span class="co">## mse.test.mean=29.4228023</span>
<span class="co">## </span>
<span class="co">## $regr.lm.featsel[[2]]</span>
<span class="co">## FeatSel result:</span>
<span class="co">## Features (9): zn, indus, chas, nox, rm, dis, ptratio, b, lstat</span>
<span class="co">## mse.test.mean=26.1964766</span></code></pre></div>
<p>You can access results for individual learners and tasks and inspect them further.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">feats</span> <span class="op">=</span> <span class="fu"><a href="../../reference/getBMRFeatSelResults.html">getBMRFeatSelResults</a></span><span class="op">(</span><span class="va">res</span>, learner.id <span class="op">=</span> <span class="st">"regr.lm.featsel"</span>, drop <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># Selected features in the first outer resampling iteration</span>
<span class="va">feats</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">x</span>
<span class="co">## [1] "indus"   "rm"      "age"     "dis"     "ptratio" "b"       "lstat"</span>

<span class="co"># Resampled performance of the selected feature subset on the first inner training set</span>
<span class="va">feats</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">y</span>
<span class="co">## mse.test.mean </span>
<span class="co">##       29.4228</span></code></pre></div>
<p>As for tuning, you can extract the optimization paths. The resulting <code>data.frame</code>s contain, among others, binary columns for all features, indicating if they were included in the linear regression model, and the corresponding performances. <code><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult()</a></code> gives a clearer overview.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">opt.paths</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">feats</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">opt.path</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">opt.paths</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">opt.paths</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="co">##   crim zn indus chas nox rm age dis rad tax ptratio b lstat mse.test.mean dob</span>
<span class="co">## 1    0  0     0    0   0  0   0   0   0   0       0 0     0      80.74823   1</span>
<span class="co">## 2    1  0     0    0   0  0   0   0   0   0       0 0     0      70.11222   2</span>
<span class="co">## 3    0  1     0    0   0  0   0   0   0   0       0 0     0      71.63520   2</span>
<span class="co">## 4    0  0     1    0   0  0   0   0   0   0       0 0     0      64.69041   2</span>
<span class="co">## 5    0  0     0    1   0  0   0   0   0   0       0 0     0      83.04175   2</span>
<span class="co">## 6    0  0     0    0   1  0   0   0   0   0       0 0     0      68.37808   2</span>
<span class="co">##   eol error.message</span>
<span class="co">## 1   2          &lt;NA&gt;</span>
<span class="co">## 2   2          &lt;NA&gt;</span>
<span class="co">## 3   2          &lt;NA&gt;</span>
<span class="co">## 4   2          &lt;NA&gt;</span>
<span class="co">## 5   2          &lt;NA&gt;</span>
<span class="co">## 6   2          &lt;NA&gt;</span>

<span class="fu"><a href="../../reference/analyzeFeatSelResult.html">analyzeFeatSelResult</a></span><span class="op">(</span><span class="va">feats</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>
<span class="co">## Features         : 7</span>
<span class="co">## Performance      : mse.test.mean=29.4228023</span>
<span class="co">## indus, rm, age, dis, ptratio, b, lstat</span>
<span class="co">## </span>
<span class="co">## Path to optimum:</span>
<span class="co">## - Features:    0  Init   :                       Perf = 80.748  Diff: NA  *</span>
<span class="co">## - Features:    1  Add    : lstat                 Perf = 37.629  Diff: 43.119  *</span>
<span class="co">## - Features:    2  Add    : rm                    Perf = 32.289  Diff: 5.3397  *</span>
<span class="co">## - Features:    3  Add    : dis                   Perf = 31.4  Diff: 0.88931  *</span>
<span class="co">## - Features:    4  Add    : indus                 Perf = 30.321  Diff: 1.0794  *</span>
<span class="co">## - Features:    5  Add    : ptratio               Perf = 29.775  Diff: 0.54598  *</span>
<span class="co">## - Features:    6  Add    : b                     Perf = 29.469  Diff: 0.3058  *</span>
<span class="co">## - Features:    7  Add    : age                   Perf = 29.423  Diff: 0.046036  *</span>
<span class="co">## </span>
<span class="co">## Stopped, because no improving feature was found.</span></code></pre></div>
</div>
<div id="example-3-one-task-two-learners-feature-filtering-with-tuning" class="section level2">
<h2 class="hasAnchor">
<a href="#example-3-one-task-two-learners-feature-filtering-with-tuning" class="anchor"></a>Example 3: One task, two learners, feature filtering with tuning</h2>
<p>Here is a minimal example for feature filtering with tuning of the feature subset size.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Feature filtering with tuning in the inner resampling loop</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeFilterWrapper.html">makeFilterWrapper</a></span><span class="op">(</span>learner <span class="op">=</span> <span class="st">"regr.lm"</span>, fw.method <span class="op">=</span> <span class="st">"FSelectorRcpp_information.gain"</span><span class="op">)</span>
<span class="va">ps</span> <span class="op">=</span> <span class="fu">makeParamSet</span><span class="op">(</span><span class="fu">makeDiscreteParam</span><span class="op">(</span><span class="st">"fw.abs"</span>, values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span><span class="op">(</span><span class="fu"><a href="../../reference/getTaskNFeats.html">getTaskNFeats</a></span><span class="op">(</span><span class="va">bh.task</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">ctrl</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">inner</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"CV"</span>, iter <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">lrn</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeTuneWrapper.html">makeTuneWrapper</a></span><span class="op">(</span><span class="va">lrn</span>,
  resampling <span class="op">=</span> <span class="va">inner</span>, par.set <span class="op">=</span> <span class="va">ps</span>, control <span class="op">=</span> <span class="va">ctrl</span>,
  show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>

<span class="co"># Learners</span>
<span class="va">lrns</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"regr.rpart"</span>, <span class="va">lrn</span><span class="op">)</span>

<span class="co"># Outer resampling loop</span>
<span class="va">outer</span> <span class="op">=</span> <span class="fu"><a href="../../reference/makeResampleDesc.html">makeResampleDesc</a></span><span class="op">(</span><span class="st">"Subsample"</span>, iter <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="va">res</span> <span class="op">=</span> <span class="fu"><a href="../../reference/benchmark.html">benchmark</a></span><span class="op">(</span>tasks <span class="op">=</span> <span class="va">bh.task</span>, learners <span class="op">=</span> <span class="va">lrns</span>, resampling <span class="op">=</span> <span class="va">outer</span>, show.info <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="co">## Warning in .information_gain.data.frame(x = x, y = y, type = type, equal =</span>
<span class="co">## equal, : Dependent variable is a numeric! It will be converted to factor with</span>
<span class="co">## simple factor(y). We do not discretize dependent variable in FSelectorRcpp by</span>
<span class="co">## default! You can choose equal frequency binning discretization by setting equal</span>
<span class="co">## argument to TRUE.</span>

<span class="va">res</span>
<span class="co">##                 task.id             learner.id mse.test.mean</span>
<span class="co">## 1 BostonHousing-example             regr.rpart      22.16021</span>
<span class="co">## 2 BostonHousing-example regr.lm.filtered.tuned      27.79428</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Performances on individual outer test data sets</span>
<span class="fu"><a href="../../reference/getBMRPerformances.html">getBMRPerformances</a></span><span class="op">(</span><span class="va">res</span>, as.df <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">##                 task.id             learner.id iter      mse</span>
<span class="co">## 1 BostonHousing-example             regr.rpart    1 23.14016</span>
<span class="co">## 2 BostonHousing-example             regr.rpart    2 29.91067</span>
<span class="co">## 3 BostonHousing-example             regr.rpart    3 13.42981</span>
<span class="co">## 4 BostonHousing-example regr.lm.filtered.tuned    1 29.75924</span>
<span class="co">## 5 BostonHousing-example regr.lm.filtered.tuned    2 38.05312</span>
<span class="co">## 6 BostonHousing-example regr.lm.filtered.tuned    3 15.57047</span></code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Patrick Schratz, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: 'e300ecafdf04fe1199e3339c825ce7d0',
    indexName: 'mlr',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
